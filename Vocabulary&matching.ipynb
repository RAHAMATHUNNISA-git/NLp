{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Vocabulary and Matching\n",
        "So far we've seen how a body of text is divided into tokens, and how individual tokens are parsed and tagged with parts of speech, dependencies and lemmas."
      ],
      "metadata": {
        "id": "S9cRCVLr2RWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule-based Matching\n",
        "spaCy offers a rule-matching tool called `Matcher` that allows you to build a library of token patterns, then match those patterns against a Doc object to return a list of found matches. You can match on any part of the token including text and annotations, and you can add multiple patterns to the same matcher.\n",
        "\n",
        "For more: https://spacy.io/usage/linguistic-features#section-rule-based-matching\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "umZW-kDl3x-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#perform standard import\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "nHxPuvWs2R8o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RFuAR62-z33g"
      },
      "outputs": [],
      "source": [
        "#import the matcher library\n",
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"<font color=green>Here `matcher` is an object that pairs to the current `Vocab` object. We can add and remove specific named matchers to `matcher` as needed.</font>"
      ],
      "metadata": {
        "id": "hOoLUlWf5q1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating patterns\n",
        "In literature, the phrase 'solar power' might appear as one word or two, with or without a hyphen. In this section we'll develop a matcher named 'SolarPower' that finds all three:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5x55yrOr5wSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern1= [{'LOWER':'solarpower'}]\n",
        "pattern2= [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n",
        "pattern3= [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}]"
      ],
      "metadata": {
        "id": "3SLffx395iSF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matcher.add('SolarPower', [pattern1, pattern2, pattern3])"
      ],
      "metadata": {
        "id": "PTb_01wg5iWq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"Let's break this down:\n",
        "* `pattern1` looks for a single token whose lowercase text reads 'solarpower'\n",
        "* `pattern2` looks for two adjacent tokens that read 'solar' and 'power' in that order\n",
        "* `pattern3` looks for three adjacent tokens, with a middle token that can be any punctuation.<font color=green>*</font>"
      ],
      "metadata": {
        "id": "1hG6QbRz9qYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=green>\\* Remember that single spaces are not tokenized, so they don't count as punctuation.</font>\n",
        "<br>Once we define our patterns, we pass them into `matcher` with the name 'SolarPower', and set *callbacks* to `None` (more on callbacks later).\n"
      ],
      "metadata": {
        "id": "hCqfCIBp9uir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying the matcher to a Doc object\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "J3VXapoM-Muc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'The Solar Power industry continues to grow as demand\\\n",
        "for solarpower increases. Solar-power cars are gaining popularity')"
      ],
      "metadata": {
        "id": "QHoRhzAB5ia6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "found_matches = matcher(doc)\n",
        "print(found_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlIhtBex5iet",
        "outputId": "54919b6c-fb53-408a-8b58-8e1f2ff98cbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(8656102463236116519, 1, 3), (8656102463236116519, 9, 10), (8656102463236116519, 12, 15)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"`matcher` returns a list of tuples. Each tuple contains an ID for the match, with start & end tokens that map to the span `doc[start:end]`\"\"\""
      ],
      "metadata": {
        "id": "VlPnsQL-w5tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for match_id, start, end in found_matches:\n",
        "  string_id = nlp.vocab.strings[match_id]   #get string representation\n",
        "  span = doc[start:end]                     #get the matched span\n",
        "  print(match_id, string_id, start, end, span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3hkPYe4w1DQ",
        "outputId": "a3da17a9-e507-4a39-8b3a-b001f1b3b579"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8656102463236116519 SolarPower 1 3 Solar Power\n",
            "8656102463236116519 SolarPower 9 10 solarpower\n",
            "8656102463236116519 SolarPower 12 15 Solar-power\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine the patterns:\n",
        "pattern1 = [{'LOWER': 'solarpower'}]\n",
        "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'power'}]"
      ],
      "metadata": {
        "id": "H7QKZKkP2sJk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = [{\"LOWER\": \"solar\"}, {\"LOWER\": \"power\"}]\n",
        "matcher.add(\"SolarPower\", [pattern])"
      ],
      "metadata": {
        "id": "5qVbD4uB3cnH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the old patterns to avoid duplication:\n",
        "matcher.remove('SolarPower')"
      ],
      "metadata": {
        "id": "to3u33p92sSE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add the new set of patterns to the 'solarpower' matcher:\n",
        "matcher.add('solarpower',[pattern1,pattern2])"
      ],
      "metadata": {
        "id": "mfJSO8HW2sdm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "id02P_P24b0Z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "found_matches = matcher(doc)\n",
        "print(found_matches)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDYIlZdv5S0u",
        "outputId": "f34f79d7-b1ee-48ab-bee4-a96ee24bee97"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-977e0611bcdd>:1: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
            "  found_matches = matcher(doc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"The `match_id` is simply the hash value of the `string_ID` 'SolarPower'\n",
        "\n",
        "### Setting pattern options and quantifiers\n",
        "You can make token rules optional by passing an `'OP':'*'` argument. This lets us streamline our patterns list:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "U1hGTqbIyqev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following quantifiers can be passed to the `'OP'` key:\n",
        "<table><tr><th>OP</th><th>Description</th></tr>\n",
        "\n",
        "<tr ><td><span >\\!</span></td><td>Negate the pattern, by requiring it to match exactly 0 times</td></tr>\n",
        "<tr ><td><span >?</span></td><td>Make the pattern optional, by allowing it to match 0 or 1 times</td></tr>\n",
        "<tr ><td><span >\\+</span></td><td>Require the pattern to match 1 or more times</td></tr>\n",
        "<tr ><td><span >\\*</span></td><td>Allow the pattern to match zero or more times</td></tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "RTE-9yZxAK9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Be careful with lemmas!\n",
        "If we wanted to match on both 'solar power' and 'solar powered', it might be tempting to look for the *lemma* of 'powered' and expect it to be 'power'. This is not always the case! The lemma of the *adjective* 'powered' is still 'powered':\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MdrE3oq3AXuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern1 = [{'LOWER': 'solarpower'}]\n",
        "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'*'}, {'LEMMA': 'power'}]   #change this pattern"
      ],
      "metadata": {
        "id": "Cl5lZosA2prn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matcher.add('Solarpower',[pattern1, pattern2])"
      ],
      "metadata": {
        "id": "RgnXq83X5iic"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc2 = nlp(u'Solar-powered energy runs solar-powered cars.')"
      ],
      "metadata": {
        "id": "2JqJqbeQ7jF3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "found_matches = matcher(doc2)"
      ],
      "metadata": {
        "id": "xsXiOtQl74_h"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(found_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLqH6sPg75DO",
        "outputId": "5ba348ad-3d21-4a77-badf-87e9453a8522"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(6544436658971563323, 0, 3), (6544436658971563323, 5, 8)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"<font color=green>The matcher found the first occurrence because the lemmatizer treated 'Solar-powered' as a verb, but not the second as it considered it an adjective.<br>For this case it may be better to set explicit token patterns.</font>\"\"\""
      ],
      "metadata": {
        "id": "lOhWiy_D8L2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern1 = [{'LOWER' : 'solarpower'}]\n",
        "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT':True, 'OP': '*'},{'LOWER': 'power'}]\n",
        "pattern3 = [{'LOWER': 'solarpowered'}]\n",
        "pattern4 = [{'LOWER' : 'solar'}, {'IS_PUNCT': True, 'OP':'*'},{'LOWER': 'powered'}]"
      ],
      "metadata": {
        "id": "lZ278ds175GR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removew the old patterns to avoid duplication:\n",
        "matcher.remove('Solarpower')"
      ],
      "metadata": {
        "id": "KxMjyjZw75JH"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matcher.add('Solarpower',[pattern1, pattern2, pattern3, pattern4])"
      ],
      "metadata": {
        "id": "eRvuquNTCRQc"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "found_matches = matcher(doc2)"
      ],
      "metadata": {
        "id": "okZ_J8UTCest"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(found_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_irHQiJACe3a",
        "outputId": "a5da8e86-8df9-4686-fee7-fe0034c2806b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(6544436658971563323, 0, 3), (6544436658971563323, 5, 8)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"## Other token attributes\n",
        "Besides lemmas, there are a variety of token attributes we can use to determine matching rules:\n",
        "<table><tr><th>Attribute</th><th>Description</th></tr>\n",
        "\n",
        "<tr ><td><span >`ORTH`</span></td><td>The exact verbatim text of a token</td></tr>\n",
        "<tr ><td><span >`LOWER`</span></td><td>The lowercase form of the token text</td></tr>\n",
        "<tr ><td><span >`LENGTH`</span></td><td>The length of the token text</td></tr>\n",
        "<tr ><td><span >`IS_ALPHA`, `IS_ASCII`, `IS_DIGIT`</span></td><td>Token text consists of alphanumeric characters, ASCII characters, digits</td></tr>\n",
        "<tr ><td><span >`IS_LOWER`, `IS_UPPER`, `IS_TITLE`</span></td><td>Token text is in lowercase, uppercase, titlecase</td></tr>\n",
        "<tr ><td><span >`IS_PUNCT`, `IS_SPACE`, `IS_STOP`</span></td><td>Token is punctuation, whitespace, stop word</td></tr>\n",
        "<tr ><td><span >`LIKE_NUM`, `LIKE_URL`, `LIKE_EMAIL`</span></td><td>Token text resembles a number, URL, email</td></tr>\n",
        "<tr ><td><span >`POS`, `TAG`, `DEP`, `LEMMA`, `SHAPE`</span></td><td>The token's simple and extended part-of-speech tag, dependency label, lemma, shape</td></tr>\n",
        "<tr ><td><span >`ENT_TYPE`</span></td><td>The token's entity label</td></tr>\n",
        "\n",
        "</table>"
      ],
      "metadata": {
        "id": "J2go01qxD69H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token wildcard\n",
        "You can pass an empty dictionary `{}` as a wildcard to represent **any token**. For example, you might want to retrieve hashtags without knowing what might follow the `#` character:\n",
        ">`[{'ORTH': '#'}, {}]`"
      ],
      "metadata": {
        "id": "fakYE4Z7EC2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PhraseMatcher\n",
        "In the above section we used token patterns to perform rule-based matching. An alternative - and often more efficient - method is to match on terminology lists. In this case we use PhraseMatcher to create a Doc object from a list of phrases, and pass that into `matcher` instead.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hVYnlJyqFQfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#perform standard imports,reset nlp\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "4TfsW_CCCe64"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')"
      ],
      "metadata": {
        "id": "A23i4PhQCe-L"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms = ['Galaxy Note', 'iphone 11', 'iphone XS', 'Google Pixel']\n",
        "patterns = [nlp(text) for text in terms]\n",
        "matcher.add(\"Terminologist\", None, *patterns)"
      ],
      "metadata": {
        "id": "ElScw7CDCfBB"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrowed from https://daringfireball.net/linked/2019/09/21/patel-11-pro\n",
        "text_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\n",
        "               \"photography tests pitting the iPhone 11 Pro against the \"\n",
        "               \"Galaxy Note 10 Plus and last yearâ€™s iPhone XS and Google Pixel 3.\")\n",
        "matches = matcher(text_doc)\n",
        "print(matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8TZguB0Hz_Q",
        "outputId": "348a3521-daab-428e-b9df-6e6f87cd38cd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(13858836701261257149, 17, 19), (13858836701261257149, 22, 24), (13858836701261257149, 30, 32), (13858836701261257149, 33, 35)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_id, start, end = matches[1]\n",
        "print(nlp.vocab.strings[match_id], text_doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFZ0y8jNIrh6",
        "outputId": "0ce5cf06-7ba1-49f0-ead4-c98073f9d046"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Terminologist Galaxy Note\n"
          ]
        }
      ]
    }
  ]
}